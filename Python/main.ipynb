{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feeding costs 11.875 and Harvesting costs 4.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\intelpython310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # disable infos\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"]=\"1\" # make sure onednn is used on CPU\n",
    "# tf.config.set_visible_devices([], 'GPU') # GPU improves c-times much\n",
    "\n",
    "T=3.0\n",
    "N=int(T*2*12)\n",
    "Nsim = 10\n",
    "# N=int(T*4*12) # no real difference\n",
    "# Nsim = 5\n",
    "r=0.0303\n",
    "dtype=np.float32\n",
    "seed=1\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "t=np.linspace(0,T,N*Nsim,endpoint=True,dtype=dtype).reshape((-1,1))\n",
    "t=tf.constant(t)\n",
    "\n",
    "from Commodities import Schwartz2Factor\n",
    "'Salmon'\n",
    "# mu, sigma1, sigma2, kappa, alpha, lambda, rho, delta0, P0\n",
    "# salmonParam=[0.12, 0.23, 0.75, 2.6, 0.02, 0.01, 0.9, 0.57, 95] # down,down\n",
    "salmonParam=[0.12, 0.23, 0.75, 2.6, 0.02, 0.2, 0.9, 0.57, 95] # down,up\n",
    "# salmonParam=[0.12, 0.23, 0.75, 2.6, 0.02, 0.6, 0.9, 0.57, 95] # up,up\n",
    "\n",
    "'Soy'\n",
    "# mu, sigma1, sigma2, kappa, alpha, lambda, rho, delta0, P0\n",
    "# soyParam=[0.15, 0.5, 0.4, 1.2, 0.06, 0.14, 0.44, 0.0, 1] # low vol\n",
    "soyParam=[0.15, 1, 0.4, 1.2, 0.06, 0.14, 0.44, 0.0, 1] # medium vol\n",
    "# soyParam=[0.15, 2, 0.4, 1.2, 0.06, 0.14, 0.44, 0.0, 1] # high vol\n",
    "\n",
    "'Risk neutral dynamics'\n",
    "salmonParam[0]=r\n",
    "soyParam[0]=r\n",
    "\n",
    "\"Fish feeding 25% of production cost, disease 30%, harvest 10%. Total production cost = 50% of price = labor, smolt, ...\"\n",
    "salmonPrice=salmonParam[-1] #NOK/KG\n",
    "harvestingCosts=salmonPrice*0.5*0.1 # roughly 10%\n",
    "feedingCosts=salmonPrice*0.5*0.25\n",
    "initialSalmon=0.5*salmonPrice+feedingCosts+harvestingCosts #we add the costs to salmon price since they are respected in the model, other costs are fixed and thus removed\n",
    "salmonParam[-1]=initialSalmon\n",
    "print(f'Feeding costs {feedingCosts} and Harvesting costs {harvestingCosts}')\n",
    "\n",
    "\n",
    "soy=Schwartz2Factor(soyParam,t,dtype=dtype)\n",
    "salmon=Schwartz2Factor(salmonParam,t,dtype=dtype)\n",
    "\n",
    "\n",
    "from Harvest import Harvest\n",
    "hc = harvestingCosts\n",
    "harvest = Harvest(hc)\n",
    "\n",
    "from Growth import Bertalanffy\n",
    "wInf=6\n",
    "a=1.113\n",
    "b=1.097\n",
    "c=1.43\n",
    "growth = Bertalanffy(t,wInf,a,b,c)\n",
    "\n",
    "from Price import Price\n",
    "price = Price(salmon)\n",
    "\n",
    "from Feed import StochFeed,DetermFeed\n",
    "cr=1.1\n",
    "fc=feedingCosts\n",
    "feed_s = StochFeed(fc,cr,r,t,soy)\n",
    "feed_d = DetermFeed(fc,cr,r,t,soy)\n",
    "\n",
    "from Mortality import ConstMortatlity,HostParasite,DetermHostParasite\n",
    "# n0=10000\n",
    "# m=0.1\n",
    "# mort = ConstMortatlity(t,n0,m) # not comparable to the other models, because of neglected treatment costs\n",
    "\n",
    "params=[0.05,0.1,8.71,0.05]\n",
    "beta=[0.0835,0.0244]\n",
    "H0=10000.0\n",
    "P0=1\n",
    "mort_s = HostParasite(t,params,beta,H0,P0)\n",
    "mort_d = DetermHostParasite(t,params,beta,H0,P0)\n",
    "\n",
    "from FishFarm import fishFarm\n",
    "farm_ss = fishFarm(growth,feed_s,price,harvest,mort_s,stride=Nsim,seed=seed)\n",
    "farm_sd = fishFarm(growth,feed_s,price,harvest,mort_d,stride=Nsim,seed=seed)\n",
    "farm_ds = fishFarm(growth,feed_d,price,harvest,mort_s,stride=Nsim,seed=seed)\n",
    "farm_dd = fishFarm(growth,feed_d,price,harvest,mort_d,stride=Nsim,seed=seed)\n",
    "\n",
    "from OptimalStopping import Polynomial,DeepOptS,LSMC\n",
    "batch_size=2**12 #need to fix it for simplicity\n",
    "batches=20 # not so relevant since we make pathwise comparison, only relevant for value of opt stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73, 81920, 6)\n"
     ]
    }
   ],
   "source": [
    "farm_ss.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "X_ss,V_ss,Vh_ss,ft_ss = farm_ss.generateFishFarm(batch_size*batches) # make sure to evaluate on same data and compiles all code for generating data\n",
    "X_ss=np.array(X_ss)\n",
    "V_ss=np.array(V_ss)\n",
    "Vh_ss=np.array(Vh_ss)\n",
    "ft_ss=np.array(ft_ss)\n",
    "print(X_ss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73, 81920, 4)\n"
     ]
    }
   ],
   "source": [
    "farm_sd.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "X_sd,V_sd,Vh_sd,ft_sd = farm_sd.generateFishFarm(batch_size*batches) # make sure to evaluate on same data and compiles all code for generating data\n",
    "X_sd=np.array(X_sd)\n",
    "V_sd=np.array(V_sd)\n",
    "Vh_sd=np.array(Vh_sd)\n",
    "ft_sd=np.array(ft_sd)\n",
    "print(X_sd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Schwartz2Factor.brownianMotionTF at 0x000002ADD394D240> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Schwartz2Factor.brownianMotionTF at 0x000002ADD394D240> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "(73, 81920, 4)\n"
     ]
    }
   ],
   "source": [
    "farm_ds.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "X_ds,V_ds,Vh_ds,ft_ds = farm_ds.generateFishFarm(batch_size*batches) # make sure to evaluate on same data and compiles all code for generating data\n",
    "X_ds=np.array(X_ds)\n",
    "V_ds=np.array(V_ds)\n",
    "Vh_ds=np.array(Vh_ds)\n",
    "ft_ds=np.array(ft_ds)\n",
    "print(X_ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73, 81920, 2)\n"
     ]
    }
   ],
   "source": [
    "farm_dd.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "X_dd,V_dd,Vh_dd,ft_dd = farm_dd.generateFishFarm(batch_size*batches) # make sure to evaluate on same data and compiles all code for generating data\n",
    "X_dd=np.array(X_dd)\n",
    "V_dd=np.array(V_dd)\n",
    "Vh_dd=np.array(Vh_dd)\n",
    "ft_dd=np.array(ft_dd)\n",
    "print(X_dd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1506/1506 [01:27<00:00, 17.27epoch/s, loss=-1.98e+6, payoff=2e+6]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean stopping time 1.998138666152954 with mean value 1978377.75 in 0.8508331775665283 s\n"
     ]
    }
   ],
   "source": [
    "batches=20\n",
    "farm_ss.seed(seed+1)\n",
    "tf.random.set_seed(seed+1)\n",
    "optDeep_ss=DeepOptS(r,farm_ss.tCoarse,farm_ss.generateFishFarm,d=farm_ss.d,batch_size=batch_size)\n",
    "optDeep_ss.train(batches)\n",
    "\n",
    "tic=time.time()\n",
    "tauDOS_ss,VtauDOS_ss=optDeep_ss.evaluate(X_ss,V_ss,Vh_ss,ft_ss)\n",
    "ctimeEval=time.time()-tic\n",
    "print(f'Mean stopping time {np.mean(tauDOS_ss)} with mean value {np.mean(VtauDOS_ss)} in {ctimeEval} s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1504 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mset_seed(seed\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m optDeep_sd\u001b[39m=\u001b[39mDeepOptS(r,farm_sd\u001b[39m.\u001b[39mtCoarse,farm_sd\u001b[39m.\u001b[39mgenerateFishFarm,d\u001b[39m=\u001b[39mfarm_sd\u001b[39m.\u001b[39md,batch_size\u001b[39m=\u001b[39mbatch_size)\n\u001b[1;32m----> 5\u001b[0m optDeep_sd\u001b[39m.\u001b[39;49mtrain(batches)\n\u001b[0;32m      7\u001b[0m tic\u001b[39m=\u001b[39mtime\u001b[39m.\u001b[39mtime()\n\u001b[0;32m      8\u001b[0m tauDOS_sd,VtauDOS_sd\u001b[39m=\u001b[39moptDeep_sd\u001b[39m.\u001b[39mevaluate(X_sd,V_sd,Vh_sd,ft_sd)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\Documents\\GitHub\\AquacultureStochasticMortality\\Python\\OptimalStopping.py:215\u001b[0m, in \u001b[0;36mDeepOptS.train\u001b[1;34m(self, batches)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m,batches:\u001b[39mint\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[39m# defining the dataset in init is faster for some reason\u001b[39;00m\n\u001b[1;32m--> 215\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset,epochs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_steps,steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[TqdmCallback(verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)],\n\u001b[0;32m    216\u001b[0m                    workers\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m    217\u001b[0m                    use_multiprocessing\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\intelpython310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\intelpython310\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1385\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\intelpython310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\intelpython310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\intelpython310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:986\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    982\u001b[0m   _, _, _, filtered_flat_args \u001b[39m=\u001b[39m \\\n\u001b[0;32m    983\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    984\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    985\u001b[0m   \u001b[39m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[1;32m--> 986\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_concrete_stateful_fn\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    987\u001b[0m       filtered_flat_args, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_concrete_stateful_fn\u001b[39m.\u001b[39;49mcaptured_inputs)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    989\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfn_with_cond\u001b[39m(inner_args, inner_kwds, inner_filtered_flat_args):\n\u001b[0;32m    990\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\intelpython310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1854\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\intelpython310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\intelpython310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batches=20\n",
    "farm_sd.seed(seed+1)\n",
    "tf.random.set_seed(seed+1)\n",
    "optDeep_sd=DeepOptS(r,farm_sd.tCoarse,farm_sd.generateFishFarm,d=farm_sd.d,batch_size=batch_size)\n",
    "optDeep_sd.train(batches)\n",
    "\n",
    "tic=time.time()\n",
    "tauDOS_sd,VtauDOS_sd=optDeep_sd.evaluate(X_sd,V_sd,Vh_sd,ft_sd)\n",
    "ctimeEval=time.time()-tic\n",
    "print(f'Mean stopping time {np.mean(tauDOS_sd)} with mean value {np.mean(VtauDOS_sd)} in {ctimeEval} s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1504/1504 [00:45<00:00, 33.10epoch/s, loss=-1.9e+6, payoff=1.92e+6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean stopping time 2.0189480781555176 with mean value 1908650.0 in 0.6957533359527588 s\n"
     ]
    }
   ],
   "source": [
    "batches=20\n",
    "farm_ds.seed(seed+1)\n",
    "tf.random.set_seed(seed+1)\n",
    "optDeep_ds=DeepOptS(r,farm_ds.tCoarse,farm_ds.generateFishFarm,d=farm_ds.d,batch_size=batch_size)\n",
    "optDeep_ds.train(batches)\n",
    "\n",
    "tic=time.time()\n",
    "tauDOS_ds,VtauDOS_ds=optDeep_ds.evaluate(X_ds,V_ds,Vh_ds,ft_ds)\n",
    "ctimeEval=time.time()-tic\n",
    "print(f'Mean stopping time {np.mean(tauDOS_ds)} with mean value {np.mean(VtauDOS_ds)} in {ctimeEval} s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1502/1502 [00:44<00:00, 33.65epoch/s, loss=-1.88e+6, payoff=1.9e+6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean stopping time 2.013272762298584 with mean value 1885143.75 in 0.5974786281585693 s\n"
     ]
    }
   ],
   "source": [
    "batches=20\n",
    "farm_dd.seed(seed+1)\n",
    "tf.random.set_seed(seed+1)\n",
    "optDeep_dd=DeepOptS(r,farm_dd.tCoarse,farm_dd.generateFishFarm,d=farm_dd.d,batch_size=batch_size)\n",
    "optDeep_dd.train(batches)\n",
    "\n",
    "tic=time.time()\n",
    "tauDOS_dd,VtauDOS_dd=optDeep_dd.evaluate(X_dd,V_dd,Vh_dd,ft_dd)\n",
    "ctimeEval=time.time()-tic\n",
    "print(f'Mean stopping time {np.mean(tauDOS_dd)} with mean value {np.mean(VtauDOS_dd)} in {ctimeEval} s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean tau: [1.99837093] with mean 1978377.7242798656 with ratio 1.0\n",
      "Mean tau: [1.99876976] with mean 1960509.148033987 with ratio 1.00911425292955\n",
      "Mean tau: [2.01919193] with mean 1907920.1222056947 with ratio 1.0369290104203717\n",
      "Mean tau: [2.01350842] with mean 1887501.994416094 with ratio 1.0481460311738025\n"
     ]
    }
   ],
   "source": [
    "tComp,Vcomp = fishFarm.compareStoppingTimes(V_ss,[tauDOS_ss,tauDOS_sd,tauDOS_ds,tauDOS_dd],np.array(farm_ss.tCoarse))\n",
    "for i in range(0,len(tComp)):\n",
    "    print(f'Mean tau: {tComp[i]} with mean {Vcomp[i]} with ratio {Vcomp[0]/Vcomp[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean stopping time 1.9465739727020264 with mean value 1948030.375 in 6.378003120422363 s\n",
      "Mean stopping time 2.018662452697754 with mean value 1960095.625 in 1.914052963256836 s\n",
      "Mean stopping time 1.9495112895965576 with mean value 1878285.0 in 1.9309661388397217 s\n",
      "Mean stopping time 2.039482831954956 with mean value 1894509.0 in 1.8499760627746582 s\n"
     ]
    }
   ],
   "source": [
    "basis_ss = Polynomial(deg=2,dtype=dtype)\n",
    "basis_sd = Polynomial(deg=2,dtype=dtype)\n",
    "basis_ds = Polynomial(deg=2,dtype=dtype)\n",
    "basis_dd = Polynomial(deg=2,dtype=dtype)\n",
    "optLSMC_ss=LSMC(r,farm_ss.tCoarse,farm_ss.generateFishFarm,basis_ss,batch_size=batch_size)\n",
    "optLSMC_sd=LSMC(r,farm_sd.tCoarse,farm_sd.generateFishFarm,basis_sd,batch_size=batch_size)\n",
    "optLSMC_ds=LSMC(r,farm_ds.tCoarse,farm_ds.generateFishFarm,basis_ds,batch_size=batch_size)\n",
    "optLSMC_dd=LSMC(r,farm_dd.tCoarse,farm_dd.generateFishFarm,basis_dd,batch_size=batch_size)\n",
    "\n",
    "tic=time.time()\n",
    "tau_ss,Vtau_ss=optLSMC_ss.evaluate(X_ss,V_ss,Vh_ss,ft_ss)\n",
    "ctimeEval=time.time()-tic\n",
    "print(f'Mean stopping time {np.mean(tau_ss)} with mean value {np.mean(Vtau_ss)} in {ctimeEval} s')\n",
    "\n",
    "tic=time.time()\n",
    "tau_sd,Vtau_sd=optLSMC_sd.evaluate(X_sd,V_sd,Vh_sd,ft_sd)\n",
    "ctimeEval=time.time()-tic\n",
    "print(f'Mean stopping time {np.mean(tau_sd)} with mean value {np.mean(Vtau_sd)} in {ctimeEval} s')\n",
    "\n",
    "tic=time.time()\n",
    "tau_ds,Vtau_ds=optLSMC_ds.evaluate(X_ds,V_ds,Vh_ds,ft_ds)\n",
    "ctimeEval=time.time()-tic\n",
    "print(f'Mean stopping time {np.mean(tau_ds)} with mean value {np.mean(Vtau_ds)} in {ctimeEval} s')\n",
    "\n",
    "tic=time.time()\n",
    "tau_dd,Vtau_dd=optLSMC_dd.evaluate(X_dd,V_dd,Vh_dd,ft_dd)\n",
    "ctimeEval=time.time()-tic\n",
    "print(f'Mean stopping time {np.mean(tau_dd)} with mean value {np.mean(Vtau_dd)} in {ctimeEval} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean tau: 1.94657412195902 with mean 1948030.4512927532 with ratio 1.0\n",
      "Mean tau: 2.0186626687875107 with mean 1963097.397609949 with ratio 0.9923249114712598\n",
      "Mean tau: 1.9495114495824963 with mean 1877563.9442260743 with ratio 1.0375308160786636\n",
      "Mean tau: 2.0394827027506834 with mean 1896992.8654403687 with ratio 1.026904469058473\n"
     ]
    }
   ],
   "source": [
    "tComp,Vcomp = fishFarm.compareStoppingTimes(V_ss,[tau_ss,tau_sd,tau_ds,tau_dd],np.array(farm_ss.tCoarse))\n",
    "for i in range(0,len(tComp)):\n",
    "    print(f'Mean tau: {tComp[i]} with mean {Vcomp[i]} with ratio {Vcomp[0]/Vcomp[i]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intelpython310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
